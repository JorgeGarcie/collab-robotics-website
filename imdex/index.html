<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Collab Robotics Group Project</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <h1>Collab Robotics Group Project</h1>
    <p>Team Members: Jorge Garcia, Ariel Bachman, Jerry Qu, Ra√∫l Molina, Jermaine Zhao</p>
  </header>
  <section id="project-goal">
    <h2>Project Goal</h2>
    <p>Our project involves integrating a state machine for logic, language processing for audio, perception for visual inputs, pose estimation, and navigation for object retrieval.</p>
  </section>
  <section id="tasks">
    <h2>Tasks</h2>
    <div>
      <h3>Task 1: Retrieve Fruit</h3>
      <p>Navigate to the object, pick it up, and return to the starting position.</p>
      <!-- IMAGE/VIDEO placeholder -->
      <p><em>IMAGE/VIDEO GOES HERE</em></p>
    </div>
    <div>
      <h3>Task 2: Pick Fruit and Place in Basket</h3>
      <p>Pick up the apple and put it in the basket.</p>
      <p><em>IMAGE/VIDEO GOES HERE</em></p>
    </div>
    <div>
      <h3>Task 3: Detect Pointing and Pick Up Fruit</h3>
      <p>The robot detects human pointing, identifies the fruit, and picks it up.</p>
      <p><em>IMAGE/VIDEO GOES HERE</em></p>
    </div>
  </section>
  <section id="methods">
    <h2>Methods</h2>
    <ul>
      <li><strong>State Machine:</strong> Handles logic with eight states.</li>
      <li><strong>Language:</strong> Processes audio and publishes detected fruit and actions.</li>
      <li><strong>Perception:</strong> Recognizes visual inputs.</li>
      <li><strong>Pose Estimation:</strong> Manages transformations and pose commands.</li>
      <li><strong>Navigation:</strong> Plans motion and retrieves objects.</li>
    </ul>
  </section>
  <footer>
    <p>Q&A</p>
  </footer>
</body>
</html>
